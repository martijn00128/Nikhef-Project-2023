{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from scipy.signal import find_peaks"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T12:48:30.665839Z",
     "start_time": "2023-07-13T12:48:30.611091Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "DATA_SOURCE = \"June 27 smaller dist 3 plate\"\n",
    "\n",
    "header_lines = 8\n",
    "data_lines = 1024\n",
    "\n",
    "prominence = 30\n",
    "width = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T12:48:30.690628Z",
     "start_time": "2023-07-13T12:48:30.658419Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "def get_data_sets(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "        total_lines = len(lines)\n",
    "        total_data_sets = math.floor(total_lines / (header_lines + data_lines))\n",
    "        file.close()\n",
    "\n",
    "    return total_data_sets - 1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T12:48:30.690930Z",
     "start_time": "2023-07-13T12:48:30.659758Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "86c5ecab-af60-4937-83ba-17888857e837",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-07-13T12:48:30.691335Z",
     "start_time": "2023-07-13T12:48:30.660764Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data_from_file(file_path):\n",
    "    animation = \"|/-\\\\\"\n",
    "    tme = 0\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Skip the initial 8 header lines\n",
    "        for _ in range(header_lines):\n",
    "            next(file)\n",
    "\n",
    "        # Initialize an empty list to store the data\n",
    "        data = []\n",
    "\n",
    "        # Read the data sets\n",
    "        for _ in range(ds):\n",
    "            # Read the data lines\n",
    "            data_set = [next(file).strip().split() for _ in range(data_lines)]\n",
    "            data_set = [float(item) for sublist in data_set for item in sublist]\n",
    "            data.append(data_set)\n",
    "\n",
    "            print(animation[tme % len(animation)], end=\"\\r\")\n",
    "            tme += 1\n",
    "\n",
    "            # Skip the next 8 header lines\n",
    "            for _ in range(header_lines):\n",
    "                next(file)\n",
    "\n",
    "    # Convert the list of data into a NumPy array\n",
    "    data_arr = np.array(data)\n",
    "    return data_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1425fadf-6fbf-452d-9676-a05863499e9d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-07-13T12:48:59.094541Z",
     "start_time": "2023-07-13T12:48:30.661168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "1\n",
      "2\n",
      "3\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# Scintillator PMTs\n",
    "trigger_file_path = \"DATA/\" + DATA_SOURCE + \"/TR_0_0.txt\"\n",
    "distant_plate_file_path = \"DATA/\" + DATA_SOURCE + \"/wave_0.txt\"\n",
    "bottom_plate_file_path = \"DATA/\" + DATA_SOURCE + \"/wave_2.txt\"\n",
    "\n",
    "print(\"start\")\n",
    "ds = get_data_sets(trigger_file_path)\n",
    "\n",
    "trigger_data_array = read_data_from_file(trigger_file_path)\n",
    "print(\"1\")\n",
    "\n",
    "distant_plate_data_array = read_data_from_file(distant_plate_file_path)\n",
    "print(\"2\")\n",
    "\n",
    "bottom_plate_data_array = read_data_from_file(bottom_plate_file_path)\n",
    "print(\"3\")\n",
    "\n",
    "data_arr_scints = np.array(\n",
    "    [trigger_data_array, bottom_plate_data_array, distant_plate_data_array]\n",
    ")\n",
    "\n",
    "# data_arr_cher = np.array([data_array_3, data_array_4, data_array_5, data_array_6, data_array_7])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e2b27f0-b54f-43d9-ab87-0645c060c874",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-07-13T12:49:01.555307Z",
     "start_time": "2023-07-13T12:48:59.153081Z"
    }
   },
   "outputs": [],
   "source": [
    "trigger_peaks = []\n",
    "bottom_peaks = []\n",
    "dist_peaks = []\n",
    "\n",
    "for i, x1 in enumerate(trigger_data_array):\n",
    "\n",
    "    peak1, properties1 = find_peaks(-x1, prominence=prominence, width=width)\n",
    "    peak2, properties2 = find_peaks(-bottom_plate_data_array[i], prominence=prominence, width=width)\n",
    "    peak3, properties3 = find_peaks(-distant_plate_data_array[i], prominence=prominence, width=width)\n",
    "\n",
    "    if peak1.size == 0:\n",
    "        trigger_peaks.append(2000)\n",
    "    else:\n",
    "        trigger_peaks.append(peak1[0])\n",
    "\n",
    "    if peak2.size == 0:\n",
    "        bottom_peaks.append(4000)\n",
    "    else:\n",
    "        bottom_peaks.append(peak2[0])\n",
    "\n",
    "    if peak3.size == 0:\n",
    "        dist_peaks.append(6000)\n",
    "    else:\n",
    "        dist_peaks.append(peak3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fac17ce6-3832-4ab2-a1f1-a0ef0045a3dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-07-13T12:49:01.570358Z",
     "start_time": "2023-07-13T12:49:01.556096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11004\n",
      "3522\n",
      "544\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "box_index = np.array([\n",
    "    i for i, x in enumerate(np.isclose(trigger_peaks, bottom_peaks, atol=1024)) if x\n",
    "])\n",
    "dist_index = np.array([\n",
    "    i for i, x in enumerate(np.isclose(trigger_peaks, dist_peaks, atol=1024)) if x\n",
    "])\n",
    "\n",
    "both_index = box_index[np.isin(box_index, dist_index)]\n",
    "\n",
    "print(ds)\n",
    "print(len(box_index))\n",
    "print(len(dist_index))\n",
    "print(len(both_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ae1eb324-86f1-46ed-a964-0c9970ce679b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "ExecuteTime": {
     "end_time": "2023-07-13T12:49:02.283140Z",
     "start_time": "2023-07-13T12:49:01.573301Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"DATA/\" + DATA_SOURCE + \"/both/trigger.txt\", \"w\") as txt_file:\n",
    "    for idx in both_index:\n",
    "        for data in data_arr_scints[0][idx]:\n",
    "            txt_file.write(\n",
    "                \"\".join(str(data)) + \"\\n\"\n",
    "            )  # works with any number of elements in a line\n",
    "with open(\"DATA/\" + DATA_SOURCE + \"/both/bottom.txt\", \"w\") as txt_file:\n",
    "    for idx in both_index:\n",
    "        for data in data_arr_scints[1][idx]:\n",
    "            txt_file.write(\n",
    "                \"\".join(str(data)) + \"\\n\"\n",
    "            )  # works with any number of elements in a line\n",
    "with open(\"DATA/\" + DATA_SOURCE + \"/both/distant.txt\", \"w\") as txt_file:\n",
    "    for idx in both_index:\n",
    "        for data in data_arr_scints[2][idx]:\n",
    "            txt_file.write(\n",
    "                \"\".join(str(data)) + \"\\n\"\n",
    "            )  # works with any number of elements in a line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def read_selected_data_from_file(file_path, index):\n",
    "    animation = \"|/-\\\\\"\n",
    "    tme = 0\n",
    "\n",
    "    skip_sets = np.ediff1d(index)\n",
    "\n",
    "    with open(file_path, \"r\") as file:\n",
    "        # Initialize an empty list to store the data\n",
    "        data = []\n",
    "\n",
    "        for _ in range(((header_lines + data_lines) * (index[0] + 1) + header_lines)):\n",
    "            next(file)\n",
    "\n",
    "        # Read the data lines\n",
    "        data_set = [next(file).strip().split() for _sets in range(data_lines)]\n",
    "        data_set = [float(item) for sublist in data_set for item in sublist]\n",
    "        data.append(data_set)\n",
    "        tme += 1\n",
    "\n",
    "        # Read the data sets\n",
    "        for _sets in skip_sets:\n",
    "            # Skip to the next interesting dataset\n",
    "            for _ in range(((header_lines + data_lines) * (_sets - 1) + header_lines)):\n",
    "                next(file)\n",
    "\n",
    "            # Read the data lines\n",
    "            data_set = [next(file).strip().split() for _sets in range(data_lines)]\n",
    "            data_set = [float(item) for sublist in data_set for item in sublist]\n",
    "            data.append(data_set)\n",
    "\n",
    "            print(animation[tme % len(animation)], end=\"\\r\")\n",
    "            tme += 1\n",
    "\n",
    "    # Convert the list of data into a NumPy array\n",
    "    data_arr = np.array(data)\n",
    "    print(\"Done\")\n",
    "    return data_arr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T12:49:02.306960Z",
     "start_time": "2023-07-13T12:49:02.290934Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Cherenkov PMTs\n",
    "file_path_3 = \"DATA/\" + DATA_SOURCE + \"/wave_3.txt\"\n",
    "file_path_4 = \"DATA/\" + DATA_SOURCE + \"/wave_4.txt\"\n",
    "file_path_5 = \"DATA/\" + DATA_SOURCE + \"/wave_5.txt\"\n",
    "file_path_6 = \"DATA/\" + DATA_SOURCE + \"/wave_6.txt\"\n",
    "file_path_7 = \"DATA/\" + DATA_SOURCE + \"/wave_7.txt\"\n",
    "\n",
    "data_array_3 = read_selected_data_from_file(file_path_3, both_index)\n",
    "data_array_4 = read_selected_data_from_file(file_path_4, both_index)\n",
    "data_array_5 = read_selected_data_from_file(file_path_5, both_index)\n",
    "data_array_6 = read_selected_data_from_file(file_path_6, both_index)\n",
    "data_array_7 = read_selected_data_from_file(file_path_7, both_index)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T12:49:11.158608Z",
     "start_time": "2023-07-13T12:49:02.307201Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "with open(\"DATA/\" + DATA_SOURCE + \"/both/short_3.txt\", \"w\") as txt_file:\n",
    "    for sets in data_array_3:\n",
    "        for data in sets:\n",
    "            txt_file.write(\n",
    "                \"\".join(str(data)) + \"\\n\"\n",
    "            )  # works with any number of elements in a line\n",
    "\n",
    "with open(\"DATA/\" + DATA_SOURCE + \"/both/short_4.txt\", \"w\") as txt_file:\n",
    "    for sets in data_array_4:\n",
    "        for data in sets:\n",
    "            txt_file.write(\n",
    "                \"\".join(str(data)) + \"\\n\"\n",
    "            )  # works with any number of elements in a line\n",
    "\n",
    "with open(\"DATA/\" + DATA_SOURCE + \"/both/short_5.txt\", \"w\") as txt_file:\n",
    "    for sets in data_array_5:\n",
    "        for data in sets:\n",
    "            txt_file.write(\n",
    "                \"\".join(str(data)) + \"\\n\"\n",
    "            )  # works with any number of elements in a line\n",
    "\n",
    "with open(\"DATA/\" + DATA_SOURCE + \"/both/short_6.txt\", \"w\") as txt_file:\n",
    "    for sets in data_array_6:\n",
    "        for data in sets:\n",
    "            txt_file.write(\n",
    "                \"\".join(str(data)) + \"\\n\"\n",
    "            )  # works with any number of elements in a line\n",
    "\n",
    "with open(\"DATA/\" + DATA_SOURCE + \"/both/short_7.txt\", \"w\") as txt_file:\n",
    "    for sets in data_array_7:\n",
    "        for data in sets:\n",
    "            txt_file.write(\n",
    "                \"\".join(str(data)) + \"\\n\"\n",
    "            )  # works with any number of elements in a line"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T12:49:12.410452Z",
     "start_time": "2023-07-13T12:49:11.158912Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-13T12:49:12.414530Z",
     "start_time": "2023-07-13T12:49:12.409881Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
